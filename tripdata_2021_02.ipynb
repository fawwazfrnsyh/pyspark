{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyspark) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('testing') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyarrow) (1.24.1)\n",
      "Requirement already satisfied: fastparquet in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2023.2.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastparquet) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastparquet) (1.24.1)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastparquet) (2.6.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastparquet) (2023.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastparquet) (22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pyarrow\n",
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "import fastparquet\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fhvhv_tripdata_2021-02.parquet', <http.client.HTTPMessage at 0x2475f9afa10>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-02.parquet\"\n",
    "filename = \"fhvhv_tripdata_2021_02.parquet\"\n",
    "urllib.request.urlretrieve(url,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('fhvhv_tripdata_2021-02.parquet')\n",
    "df.to_csv('fhvhv_tripdata_2021-02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvfhs_license_num              0\n",
       "dispatching_base_num           0\n",
       "originating_base_num     3319132\n",
       "request_datetime               1\n",
       "on_scene_datetime        3318817\n",
       "pickup_datetime                0\n",
       "dropoff_datetime               0\n",
       "PULocationID                   0\n",
       "DOLocationID                   0\n",
       "trip_miles                     0\n",
       "trip_time                      0\n",
       "base_passenger_fare            0\n",
       "tolls                          0\n",
       "bcf                            0\n",
       "sales_tax                      0\n",
       "congestion_surcharge           0\n",
       "airport_fee             11613181\n",
       "tips                           0\n",
       "driver_pay                     0\n",
       "shared_request_flag            0\n",
       "shared_match_flag              0\n",
       "access_a_ride_flag             0\n",
       "wav_request_flag               0\n",
       "wav_match_flag                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvfhs_license_num       0\n",
       "dispatching_base_num    0\n",
       "originating_base_num    0\n",
       "request_datetime        0\n",
       "on_scene_datetime       0\n",
       "pickup_datetime         0\n",
       "dropoff_datetime        0\n",
       "PULocationID            0\n",
       "DOLocationID            0\n",
       "trip_miles              0\n",
       "trip_time               0\n",
       "base_passenger_fare     0\n",
       "tolls                   0\n",
       "bcf                     0\n",
       "sales_tax               0\n",
       "congestion_surcharge    0\n",
       "airport_fee             0\n",
       "tips                    0\n",
       "driver_pay              0\n",
       "shared_request_flag     0\n",
       "shared_match_flag       0\n",
       "access_a_ride_flag      0\n",
       "wav_request_flag        0\n",
       "wav_match_flag          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"originating_base_num\"] = df[\"originating_base_num\"].fillna(\"Nan Values\")\n",
    "df[\"on_scene_datetime\"] = df[\"on_scene_datetime\"].fillna(\"Nan Values\")\n",
    "df[\"airport_fee\"] = df[\"airport_fee\"].fillna(\"Nan Values\")\n",
    "df[\"request_datetime\"] = df[\"request_datetime\"].fillna(\"Nan Values\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.show of DataFrame[_c0: string, hvfhs_license_num: string, dispatching_base_num: string, originating_base_num: string, request_datetime: string, on_scene_datetime: string, pickup_datetime: string, dropoff_datetime: string, PULocationID: string, DOLocationID: string, trip_miles: string, trip_time: string, base_passenger_fare: string, tolls: string, bcf: string, sales_tax: string, congestion_surcharge: string, airport_fee: string, tips: string, driver_pay: string, shared_request_flag: string, shared_match_flag: string, access_a_ride_flag: string, wav_request_flag: string, wav_match_flag: string]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhvhv_tripdata_2021-02.csv')\n",
    "\n",
    "df1.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvfhs_license_num               object\n",
       "dispatching_base_num            object\n",
       "originating_base_num            object\n",
       "request_datetime                object\n",
       "on_scene_datetime               object\n",
       "pickup_datetime         datetime64[ns]\n",
       "dropoff_datetime        datetime64[ns]\n",
       "PULocationID                     int64\n",
       "DOLocationID                     int64\n",
       "trip_miles                     float64\n",
       "trip_time                        int64\n",
       "base_passenger_fare            float64\n",
       "tolls                          float64\n",
       "bcf                            float64\n",
       "sales_tax                      float64\n",
       "congestion_surcharge           float64\n",
       "airport_fee                     object\n",
       "tips                           float64\n",
       "driver_pay                     float64\n",
       "shared_request_flag             object\n",
       "shared_match_flag               object\n",
       "access_a_ride_flag              object\n",
       "wav_request_flag                object\n",
       "wav_match_flag                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: string (nullable = true)\n",
      " |-- on_scene_datetime: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- trip_miles: string (nullable = true)\n",
      " |-- trip_time: string (nullable = true)\n",
      " |-- base_passenger_fare: string (nullable = true)\n",
      " |-- tolls: string (nullable = true)\n",
      " |-- bcf: string (nullable = true)\n",
      " |-- sales_tax: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      " |-- airport_fee: string (nullable = true)\n",
      " |-- tips: string (nullable = true)\n",
      " |-- driver_pay: string (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "filter_condition = col('pickup_datetime').contains('2021-02-15')\n",
    "df_15feb = df1.filter(filter_condition)\n",
    "df_15feb_count = df_15feb.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many taxi trips were there on February 15? There are: 367170 trips\n"
     ]
    }
   ],
   "source": [
    "print(f\"How many taxi trips were there on February 15? There are: {df_15feb_count} trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find the longest trip for each day?\n",
      "+-----------+--------------+\n",
      "|pickup_date|max_trip_miles|\n",
      "+-----------+--------------+\n",
      "| 2021-02-01|         99.67|\n",
      "| 2021-02-02|         98.69|\n",
      "| 2021-02-03|        99.891|\n",
      "| 2021-02-04|         99.84|\n",
      "| 2021-02-05|        99.807|\n",
      "| 2021-02-06|         99.28|\n",
      "| 2021-02-07|        99.378|\n",
      "| 2021-02-08|         99.08|\n",
      "| 2021-02-09|        99.647|\n",
      "| 2021-02-10|        98.578|\n",
      "| 2021-02-11|        99.875|\n",
      "| 2021-02-12|         99.92|\n",
      "| 2021-02-13|          99.2|\n",
      "| 2021-02-14|          99.0|\n",
      "| 2021-02-15|         99.99|\n",
      "| 2021-02-16|         99.35|\n",
      "| 2021-02-17|        99.786|\n",
      "| 2021-02-18|         97.48|\n",
      "| 2021-02-19|         98.58|\n",
      "| 2021-02-20|         98.64|\n",
      "+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_max_trip_miles = df1.groupBy(date_format(col('pickup_datetime'), 'yyyy-MM-dd') \\\n",
    "                                .alias('pickup_date')).agg(max(col('trip_miles')) \\\n",
    "                                .alias('max_trip_miles'))\n",
    "print('Find the longest trip for each day?')\n",
    "df_max_trip_miles.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|dispatching_base_num|  count|\n",
      "+--------------------+-------+\n",
      "|              B02510|3233664|\n",
      "|              B02764| 965568|\n",
      "|              B02872| 882689|\n",
      "|              B02875| 685390|\n",
      "|              B02765| 559768|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dispatch = df1.groupBy(col('dispatching_base_num')).count()\n",
    "top5_dispatch = dispatch.orderBy(col('count').desc()).limit(5)\n",
    "top5_dispatch.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat_ws, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_pair = df1.withColumn('location_pair', concat_ws('->', col('PUlocationID'), col('DOlocationID')))\n",
    "df_location_pair = df_with_pair.groupBy('location_pair').agg(count('*').alias('count'))\n",
    "top5_location_pair = df_location_pair.orderBy(col('count').desc()).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|location_pair|count|\n",
      "+-------------+-----+\n",
      "|       76->76|45041|\n",
      "|       26->26|37329|\n",
      "|       39->39|28026|\n",
      "|       61->61|25976|\n",
      "|       14->14|17934|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Find Top 5 Most common location pairs (PUlocationID and DOlocationID)')\n",
    "top5_location_pair.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
